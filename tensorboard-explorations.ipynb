{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TensorBoard for Artists\n",
    "\n",
    "TensorBoard is an incredibly powerful tool for exploring and understanding the deep neural networks you create using [TensorFlow](https://www.tensorflow.org/), PyTorch, or other high performance numerical computation libraries. This notebook is an attempt to show how one would use TensorBoard with [Keras](https://keras.io/), a friendly, high-level neural networks API written in Python.\n",
    "\n",
    "![](https://www.tensorflow.org/images/graph_vis_animation.gif)\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "* TensorFlow version ____ \n",
    "\n",
    "#### Overview of the example\n",
    "\n",
    "// Example demonstrates the use of a Convolutional 1D neural network for text classification\n",
    "\n",
    "#### Import required libraries\n",
    "\n",
    "To begin, we will import portions of several `keras` libraries.\n",
    "\n",
    "* `sequence`\n",
    "* `Sequential`\n",
    "* `Dense`, `Dropout`, and `Activation`\n",
    "* `Embedding`\n",
    "* `Conv1D`, `GlobalMaxPooling1D`\n",
    "* `imdb` is a dataset that \n",
    "* `TensorBoard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future import print_function\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.python.keras.layers import Embedding\n",
    "from tensorflow.python.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.python.keras.datasets import imdb\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters\n",
    "\n",
    "// Explanation of what each of the parameters do and why you would need them.\n",
    "\n",
    "* `max_features`\n",
    "* `maxlen`\n",
    "* `batch_size`\n",
    "* `embedding_dims`\n",
    "* `filters`\n",
    "* `kernel_size`\n",
    "* `hidden_dims`\n",
    "* `epochs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load IMDB data\n",
    "\n",
    "// Explanation of what is happening, why max_features is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up visualizations in TensorBoard\n",
    "\n",
    "// Explanation of what each of these arguments do, and how they change the outputs of the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callbacks = TensorBoard( log_dir = './Graph',\n",
    "                            histogram_freq = 100,\n",
    "                            write_grads = True,\n",
    "                            write_graph = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model\n",
    "\n",
    "// Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length = maxlen))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding = 'valid',\n",
    "                 activation = 'relu',\n",
    "                 strides = 1))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data = (x_test, y_test),\n",
    "          callbacks = [tb_callbacks])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
